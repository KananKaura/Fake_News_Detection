{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTlSmkdsJ5tnslzyJqwUNx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**FAKE NEWS DETECTION WITH BERT**"
      ],
      "metadata": {
        "id": "GNb6SqlLutZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Setting Up Google Drive"
      ],
      "metadata": {
        "id": "imfUEoVqu6sL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFvjctWu_oR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747309120255,
          "user_tz": -330,
          "elapsed": 23917,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "ff56765d-6249-48fd-8681-20c21ca39d3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Loading the Dataset"
      ],
      "metadata": {
        "id": "xPS7XZ0yvXYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Data from Google Drive\n",
        "fake_data = pd.read_csv('/content/drive/MyDrive/Fake_News_Detection/data/Fake.csv')\n",
        "true_data = pd.read_csv('/content/drive/MyDrive/Fake_News_Detection/data/True.csv')\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Fake News: {fake_data.shape}\")\n",
        "print(f\"True News: {true_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwQ1Xj9UvYau",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747309174153,
          "user_tz": -330,
          "elapsed": 4383,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "6ebcc5dc-a955-4039-ef12-4373edfcdd5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake News: (23481, 4)\n",
            "True News: (21417, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Data Preprocessing"
      ],
      "metadata": {
        "id": "c2I9OZwuvmK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Data\n",
        "fake_data['label'] = 0  # Fake = 0\n",
        "true_data['label'] = 1  # True = 1\n",
        "\n",
        "# Concatenate and Shuffle Data\n",
        "data = pd.concat([fake_data, true_data], ignore_index=True)\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Drop rows with missing text\n",
        "data.dropna(subset=['text'], inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save cleaned data\n",
        "cleaned_data_path = '/content/drive/MyDrive/Fake_News_Detection/data/cleaned_data.csv'\n",
        "data.to_csv(cleaned_data_path, index=False)\n",
        "\n",
        "print(f\"Cleaned Data saved at: {cleaned_data_path}\")\n",
        "print(f\"Total Records: {data.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE2l7YJpvjB_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747309735613,
          "user_tz": -330,
          "elapsed": 4378,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "df21f004-d4cd-495e-936c-fa25b72d8b37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Data saved at: /content/drive/MyDrive/Fake_News_Detection/data/cleaned_data.csv\n",
            "Total Records: 44898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Install Necessary Libraries"
      ],
      "metadata": {
        "id": "r3G7cMxNxthT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PE3DViIKx3-l",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747309906692,
          "user_tz": -330,
          "elapsed": 55844,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "19f7ed07-25e4-40c7-9f0a-69d21620c326"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cusparse-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12 nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Import Required Libraries"
      ],
      "metadata": {
        "id": "GamCdbWNyYbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ],
      "metadata": {
        "id": "i4s8RiUQybcF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747309965209,
          "user_tz": -330,
          "elapsed": 22181,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 6: Load Cleaned Data"
      ],
      "metadata": {
        "id": "zd5vNeVbyo-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cleaned data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Fake_News_Detection/data/cleaned_data.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pU9Vc3N7yr_e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310014024,
          "user_tz": -330,
          "elapsed": 2408,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "0bd986c3-9b23-44ec-f574-a5b24b61baa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
              "1  Trump drops Steve Bannon from National Securit...   \n",
              "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
              "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
              "4  Donald Trump heads for Scotland to reopen a go...   \n",
              "\n",
              "                                                text       subject  \\\n",
              "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
              "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
              "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
              "3  On Monday, Donald Trump once again embarrassed...          News   \n",
              "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
              "\n",
              "                  date  label  \n",
              "0    February 13, 2017      0  \n",
              "1       April 5, 2017       1  \n",
              "2  September 27, 2017       1  \n",
              "3         May 22, 2017      0  \n",
              "4       June 24, 2016       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf15301c-ab60-4efc-a71b-3c4a75ec8573\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
              "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
              "      <td>US_News</td>\n",
              "      <td>February 13, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>April 5, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
              "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 27, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
              "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
              "      <td>News</td>\n",
              "      <td>May 22, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
              "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>June 24, 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf15301c-ab60-4efc-a71b-3c4a75ec8573')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf15301c-ab60-4efc-a71b-3c4a75ec8573 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf15301c-ab60-4efc-a71b-3c4a75ec8573');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3e4c8db6-bab3-49ac-b413-0cd7c16da965\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e4c8db6-bab3-49ac-b413-0cd7c16da965')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3e4c8db6-bab3-49ac-b413-0cd7c16da965 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 44898,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38729,\n        \"samples\": [\n          \" WATCH: Dem Senator BLASTS Trump, Calls Him A Liar Live On Air\",\n          \"Trump calls for firm response to North Korea, targets Seoul on trade\",\n          \"Zimbabwe army leaves streets a month after Mugabe's ouster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38646,\n        \"samples\": [\n          \"It takes one to know one. Turkey just held a referendum that greatly expands the power of their president, Recep Tayyip Erdogan. It passed by a very narrow margin, taking Turkey on its latest step toward brutal dictatorship, and here s Donald Trump, who sources say called Erdogan to congratulate him on  winning  the referendum vote.While we re busy justifying blowing up absolutely nothing in Syria because a brutal dictator used sarin gas on his people, Trump is busy calling someone who s working hard on becoming the region s next brutal dictator to congratulate him on furthering that goal.This referendum, according to The Daily Beast, moves Turkey away from a parliamentary democracy and towards one-person rule. But what he has already done there makes the referendum more of a formality. Erdogan had already managed to form a one-party government   a move that greatly diminishes the voices of opposition.Last year, Erdogan asked Turkey s parliament to redefine the country s anti-extremism law to include politicians, journalists and members of academia. He claimed that  pro-Kurdish  politicians were inciting terrorism, and journalists and academics were spreading the info that allowed the politicians to do so. Therefore, they are all terrorists.Branding press as  the enemy  is something Trump has been trying to do here. As the Washington Post s front page motto says,  Democracy dies in darkness.  This is the darkness.And now, Erdogan is, more or less, the sole ruler of Turkey.But what does Trump care? It wouldn t be surprising to find that he wishes something like that would happen here, too, if for no other reason than it would help cement his overinflated opinion of himself as a great man who is beloved by all, with nobody left to shine a light on the truth, like, oh, say, a free press.The way the Turkey referendum was held has appalled international election monitors. According to them,  voters were not provided with adequate information, opposition voices were muzzled and the rules were changed at the last minute.  In short, this was not a truly democratic process.Good job continuing to support authoritarian rulers over true democracies, Trump. You re about as un-American as it gets.Featured image by Mark Wilson via Getty Images\",\n          \"Donald Trump just got caught lying again and there is video to prove it.When former FBI Director James Comey testified under oath in the Senate on Thursday, he recalled that Trump demanded loyalty from him before he was asked to drop the investigation of Michael Flynn and Trump s ties to Russia. The President said,  I need loyalty, I expect loyalty,  Comey testified.But when asked by ABC reporter Jon Karl if he had demanded Comey s loyalty, Trump denied the whole thing and pretended that he has never demanded loyalty from anyone in his entire life. So he said those things under oath,  Karl began.  Would you be willing to speak under oath to give your version of those events? One hundred percent,  Trump replied.  I didn t say under oath   I hardly know the man. I m not going to say, I want you to pledge allegiance. Who would do that? Who would ask a man to pledge allegiance under oath? I mean, think of it. I hardly know the man. It doesn t make sense. No, I didn t say that, and I didn t say the other. If Trump were to say this under oath he would he would be committing perjury. And CNN proved it by playing video of Trump on the campaign trail in Florida asking people in the crowd to raise their hands and pledge their loyalty to him. Keep in mind that Trump had never met anyone in that audience. But he had several discussions and meetings with Comey. In other words, Comey was not a complete stranger to him. If he was willing to ask a crowd of random people to pledge their allegiance to him, he would certainly be willing to demand loyalty from Comey.Here s the damning video via YouTube.This is yet more proof that Trump is a liar who has zero credibility. He will say anything to save his own ass.Featured image via Olivier Douliery   Pool/Getty Images\",\n          \"WASHINGTON (Reuters) - The U.S. State Department said on Monday Washington was  very concerned  by reports of violence around the Iraqi oil city of Kirkuk, which was seized by Baghdad s forces from Kurds.  We are monitoring the situation closely and call on all parties to coordinate military activities and restore calm,   State Department spokeswoman Heather Nauert said in a statement. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"politicsNews\",\n          \"worldnews\",\n          \"US_News\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2397,\n        \"samples\": [\n          \"July 3, 2016\",\n          \"Jul 29, 2015\",\n          \"Nov 28, 2016\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Split Data into Train and Test Sets"
      ],
      "metadata": {
        "id": "BglrAOO5y0e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X = data['text'].values\n",
        "y = data['label'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training Samples: {len(X_train)}\")\n",
        "print(f\"Testing Samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4fJwhyuywbG",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310029477,
          "user_tz": -330,
          "elapsed": 28,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "ae62c586-7d2a-4839-b801-d768ed464b79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples: 35918\n",
            "Testing Samples: 8980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Initialize BERT Model and Tokenizer"
      ],
      "metadata": {
        "id": "EXASqX7ky4N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize BERT Tokenizer and Model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "2421bf842c074d1b91b0cb07f09a56e1",
            "b36302f1e42642a8b9da4c6b69ae5134",
            "86142ca1e4cf46f6bb6113192b52a437",
            "7787301374cb4005a36c76e58df7fa26",
            "4b1821b16dac4722ae9c917c2ffdaf7f",
            "addbdff4f10c492b95a7978ef35ffe78",
            "1cc8f9bdad884fb3b927e83ae4bb8e42",
            "1adb76f0d71b4dfdbff31a2084cb7b51",
            "3de6465749a14f06a1b48e342dd57e93",
            "2481a81584724de4b2346708c10be554",
            "3c3c142dd22247bcad0bef7de70ccf96",
            "3c7fa20751c844898fd8f5cea1b19e0f",
            "38659920f7ca4ffeb70f2f8fda2aebf0",
            "a57839891581425c96eef6fea31e8143",
            "6a39012d75b1455e8cde1510dd4de9ff",
            "b9e102821e724a52becfbc03bcf7a8a1",
            "79c57b7769054e1ca7659ba32444b737",
            "72d59ab7535c42bea6afabc3fdbdb8ba",
            "054816db233c46779265af253a0755e6",
            "dd8cdfd8f6b94af288c1bacd70817481",
            "90b2481f012c40be8fca7ef063bf22c3",
            "d48825549c9e48749f5ebc4d8c8e1b37",
            "5072c209a14c42b493167368a3e5cc0b",
            "2257201bfd8b49d0ab334bc62b2b1b39",
            "b99ff444e2884151b7583ddf2ceaaa0c",
            "34b7b4f40c7b49719cd2207619f24ebb",
            "02df80725b034b2fb5a17625aa842f8e",
            "c05d1bb24e9a476eb51355d5d7d4dff0",
            "0d4599d0a1f74a8d8e1e2624f16805b6",
            "65d6d7d2b47846db97d7dfc1a7d13d2e",
            "3b17d34baf5b4c3498218c705d6f1264",
            "8038ba36d3cb438f939b1a9f77ce9d5c",
            "deed4fe8e43b429994ee7d18ac552e10",
            "af7c1c88767c410b839081e7274229fe",
            "78f18d273d52496aa34ae00786b4d8a3",
            "355285a31414456c95ef8d3816927f25",
            "1338908a5f444af481734e3198836079",
            "05b54a55c0a34887bc6a3a359c350d8f",
            "88ce3ee547764197a9e965153ce80067",
            "efe22586dcc0476ab033ed1690725363",
            "da9344463451416788fe6a20c136647f",
            "2068f1753eb84df19af1a3c0cc0c709f",
            "a08cb49b82d145e898ab613171f4812a",
            "f2096dc67e6e42aba1fd260a5120b3e1",
            "875d4029116b4acfa8250701cf26e013",
            "f002b5462e424e5597babb9a315c19b0",
            "8c672e9e54004848be4785e29ebe9935",
            "1f08efd0e3754a119a0525936e64ec65",
            "2cfd99f16a02473891fc77f4085626d7",
            "998f889f7bf044f18f01ee55d601ef98",
            "48f67a6af2bf4a36b545741e94522201",
            "35363d71baca4a8184187d1f08bb511b",
            "5dba5069eb4246d49bfc1d5555b5c6fe",
            "a0bd9028a6e641588618f669f03f3352",
            "1fd76bb1264e437ab0739b5523c54e74"
          ]
        },
        "id": "j9jlF69Yy7Gk",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310089726,
          "user_tz": -330,
          "elapsed": 17238,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "8dde02f9-2679-47c9-f06b-6cfc9b6a5d27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2421bf842c074d1b91b0cb07f09a56e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c7fa20751c844898fd8f5cea1b19e0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5072c209a14c42b493167368a3e5cc0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af7c1c88767c410b839081e7274229fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "875d4029116b4acfa8250701cf26e013"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Define Tokenization Function"
      ],
      "metadata": {
        "id": "NDH6dh03zCLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize data\n",
        "def tokenize_data(texts, labels):\n",
        "    input_ids, attention_masks = [], []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    return torch.cat(input_ids), torch.cat(attention_masks), torch.tensor(labels)\n"
      ],
      "metadata": {
        "id": "fD1uQQ_NzE_C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310112066,
          "user_tz": -330,
          "elapsed": 6,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        }
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Tokenize the Data"
      ],
      "metadata": {
        "id": "JxoEfKqazHTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs, train_masks, train_labels = tokenize_data(X_train, y_train)\n",
        "test_inputs, test_masks, test_labels = tokenize_data(X_test, y_test)\n",
        "\n",
        "print(f\"Train Inputs: {train_inputs.shape}, Train Masks: {train_masks.shape}, Train Labels: {train_labels.shape}\")\n",
        "print(f\"Test Inputs: {test_inputs.shape}, Test Masks: {test_masks.shape}, Test Labels: {test_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FewoQHqzJ-d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310471559,
          "user_tz": -330,
          "elapsed": 338279,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "062f2afe-7b2d-4138-e7af-e64f33691649"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Inputs: torch.Size([35918, 128]), Train Masks: torch.Size([35918, 128]), Train Labels: torch.Size([35918])\n",
            "Test Inputs: torch.Size([8980, 128]), Test Masks: torch.Size([8980, 128]), Test Labels: torch.Size([8980])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Create DataLoader for Train and Test Data"
      ],
      "metadata": {
        "id": "xh-CuTSH0ilo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "\n",
        "# Set Batch Size\n",
        "batch_size = 16\n",
        "\n",
        "# Train DataLoader\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
        "\n",
        "# Test DataLoader\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)\n",
        "\n",
        "print(f\"Train Dataloader: {len(train_dataloader)} batches\")\n",
        "print(f\"Test Dataloader: {len(test_dataloader)} batches\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVfNp_6L0zeS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310574012,
          "user_tz": -330,
          "elapsed": 64,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "8f9357fb-50ea-4d59-971b-e3d1034a9a82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataloader: 2245 batches\n",
            "Test Dataloader: 562 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Initialize Optimizer, Scheduler, and Early Stopping"
      ],
      "metadata": {
        "id": "E-IQYPQb04-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# Gradient Scaler for Mixed Precision\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Total Steps for Scheduler\n",
        "total_steps = len(train_dataloader) * 10  # 10 epochs (can be adjusted)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Early Stopping Parameters\n",
        "early_stopping_patience = 3  # Stop after 3 epochs without improvement\n",
        "best_val_loss = np.inf\n",
        "early_stopping_counter = 0\n",
        "\n",
        "print(\"Optimizer, Scheduler, and Early Stopping Initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvAe-Hd0_AB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310612202,
          "user_tz": -330,
          "elapsed": 55,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "6713df59-3fc0-408c-e5fc-61f0663f8162"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer, Scheduler, and Early Stopping Initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-052bb3f4236f>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Define Training Function with Early Stopping"
      ],
      "metadata": {
        "id": "JYzEmW951B5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_dataloader, test_dataloader, optimizer, scheduler, scaler, epochs=10):\n",
        "    global best_val_loss, early_stopping_counter\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_dataloader):\n",
        "            batch_inputs, batch_masks, batch_labels = tuple(t.to(device) for t in batch)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():  # Mixed Precision\n",
        "                outputs = model(input_ids=batch_inputs, attention_mask=batch_masks, labels=batch_labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        val_loss = evaluate_model(model, test_dataloader)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            early_stopping_counter = 0\n",
        "\n",
        "            # Save Best Model\n",
        "            model.save_pretrained('/content/drive/MyDrive/Fake_News_Detection/models/best_model')\n",
        "            tokenizer.save_pretrained('/content/drive/MyDrive/Fake_News_Detection/models/best_model')\n",
        "            print(\"✅ Best Model Saved.\")\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "            if early_stopping_counter >= early_stopping_patience:\n",
        "                print(\"Early Stopping Triggered.\")\n",
        "                break\n"
      ],
      "metadata": {
        "id": "Aay6iIgW1GrS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310659789,
          "user_tz": -330,
          "elapsed": 15,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        }
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Define Evaluation Function"
      ],
      "metadata": {
        "id": "vkH7jurq1NJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_inputs, batch_masks, batch_labels = tuple(t.to(device) for t in batch)\n",
        "            outputs = model(input_ids=batch_inputs, attention_mask=batch_masks, labels=batch_labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "YIsHNYxE1S0L",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747310694997,
          "user_tz": -330,
          "elapsed": 25,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        }
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 15: Start Training with Early Stopping"
      ],
      "metadata": {
        "id": "Qs2GK1Og1gz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Training\n",
        "train_model(model, train_dataloader, test_dataloader, optimizer, scheduler, scaler, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4W5h8-1iuo",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747314246130,
          "user_tz": -330,
          "elapsed": 3485868,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "01ee88c1-50f0-4539-d2ba-f6bb6b1fc4d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2245 [00:00<?, ?it/s]<ipython-input-17-2a92f2279dfc>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Mixed Precision\n",
            "100%|██████████| 2245/2245 [04:39<00:00,  8.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0105\n",
            "Validation Loss: 0.0059\n",
            "✅ Best Model Saved.\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:41<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0030\n",
            "Validation Loss: 0.0064\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:40<00:00,  8.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0021\n",
            "Validation Loss: 0.0025\n",
            "✅ Best Model Saved.\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:41<00:00,  7.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0010\n",
            "Validation Loss: 0.0021\n",
            "✅ Best Model Saved.\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:41<00:00,  7.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0004\n",
            "Validation Loss: 0.0008\n",
            "✅ Best Model Saved.\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:41<00:00,  7.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0005\n",
            "Validation Loss: 0.0042\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:40<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0003\n",
            "Validation Loss: 0.0003\n",
            "✅ Best Model Saved.\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:41<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0002\n",
            "Validation Loss: 0.0003\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:40<00:00,  8.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0002\n",
            "Validation Loss: 0.0005\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2245/2245 [04:40<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Loss: 0.0003\n",
            "Validation Loss: 0.0006\n",
            "Early Stopping Triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 16: Evaluate the Best Model on Test Data"
      ],
      "metadata": {
        "id": "0LV64u9DD10S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load Best Model\n",
        "model = BertForSequenceClassification.from_pretrained('/content/drive/MyDrive/Fake_News_Detection/models/best_model')\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_inputs, batch_masks, batch_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=batch_inputs, attention_mask=batch_masks)\n",
        "        preds = torch.argmax(outputs.logits, axis=1).flatten()\n",
        "\n",
        "    predictions.extend(preds.cpu().numpy())\n",
        "    true_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(true_labels, predictions))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"\\n✅ Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpOcQNfXEjkS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747314757984,
          "user_tz": -330,
          "elapsed": 68327,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "e739ff5f-7035-48ce-94bc-5048d19dec78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4710\n",
            "           1       1.00      1.00      1.00      4270\n",
            "\n",
            "    accuracy                           1.00      8980\n",
            "   macro avg       1.00      1.00      1.00      8980\n",
            "weighted avg       1.00      1.00      1.00      8980\n",
            "\n",
            "\n",
            "✅ Model Accuracy: 99.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 17: Display Test Results for Sample Texts"
      ],
      "metadata": {
        "id": "JHiBYW2AE7LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Display Predictions\n",
        "def display_test_results(model, tokenizer, test_texts, test_labels, num_samples=5):\n",
        "    model.eval()\n",
        "    print(\"\\nDisplaying Test Results on Sample Texts:\\n\")\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        text = test_texts[i]\n",
        "        label = test_labels[i]\n",
        "\n",
        "        # Tokenize and Encode\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        input_ids = encoded['input_ids'].to(device)\n",
        "        attention_mask = encoded['attention_mask'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, attention_mask=attention_mask)\n",
        "            pred_label = torch.argmax(output.logits, dim=1).item()\n",
        "\n",
        "        print(f\"Text: {text[:200]}...\")  # Display first 200 characters\n",
        "        print(f\"Actual Label: {'Fake' if label == 0 else 'True'}\")\n",
        "        print(f\"Predicted Label: {'Fake' if pred_label == 0 else 'True'}\")\n",
        "        print(\"===\" * 20)\n",
        "\n",
        "# Display Results for a Few Test Samples\n",
        "display_test_results(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    X_test[:10],   # Adjust number as needed\n",
        "    y_test[:10]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsqhtRWNFLjy",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747314866209,
          "user_tz": -330,
          "elapsed": 154,
          "user": {
            "displayName": "Kanan Kaura",
            "userId": "10610999489261602196"
          }
        },
        "outputId": "d8772997-46f9-4587-a1c6-c7e44dffdaad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying Test Results on Sample Texts:\n",
            "\n",
            "Text: Well, that didn t take long. In the short time since Americans kinda-sorta elected Donald Trump to be Pussygrabber-in-Chief, Trump has appointed a bona fide white nationalist to a high-level position ...\n",
            "Actual Label: Fake\n",
            "Predicted Label: Fake\n",
            "============================================================\n",
            "Text: (Reuters) - Republican lawmaker Devin Nunes’ investigation into whether Obama administration officials used classified intelligence reports to discredit Donald Trump’s 2016 campaign team could backfir...\n",
            "Actual Label: True\n",
            "Predicted Label: True\n",
            "============================================================\n",
            "Text: WASHINGTON (Reuters) - President Donald Trump said on Friday that churches in Texas should be able to receive money from the Federal Emergency Management Agency for helping victims of Hurricane Harvey...\n",
            "Actual Label: True\n",
            "Predicted Label: True\n",
            "============================================================\n",
            "Text: Print journalism and longstanding papers have been struggling since the advent of the internet and increased competition faced by blogs and op-ed sites. That, combined with poor understanding of marke...\n",
            "Actual Label: Fake\n",
            "Predicted Label: Fake\n",
            "============================================================\n",
            "Text: WASHINGTON (Reuters) - President Donald Trump was being briefed on Friday by House Speaker Paul Ryan about the status of voting on the Republican bill to replace Obamacare, the White House said amid s...\n",
            "Actual Label: True\n",
            "Predicted Label: True\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}